{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **SHETH L.U.J. & SIR M.V. COLLEGE**\n",
        "\n",
        "**Aayush D. Yadav | T123**\n",
        "###Practical No. 3\n",
        "**Aim:** Feature Scaling and Dummification\n",
        "* Apply feature-scaling techniques like standardization and normalization to numerical features.\n",
        "* Perform feature dummification to convert categorical variables into numerical\n",
        "representations.\n",
        "\n",
        "### **Part 1: Handling Numerical Data**\n",
        "\n",
        "**1: Import Libraries and Load Data**"
      ],
      "metadata": {
        "id": "OARW1RXfDVNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('bank.csv')\n",
        "print(\"Original Data Head:\")\n",
        "print(df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data Head:\n",
            "   age         job  marital  education default  balance housing loan  contact  \\\n",
            "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
            "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
            "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
            "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
            "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
            "\n",
            "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
            "0    5   may      1042         1     -1         0  unknown     yes  \n",
            "1    5   may      1467         1     -1         0  unknown     yes  \n",
            "2    5   may      1389         1     -1         0  unknown     yes  \n",
            "3    5   may       579         1     -1         0  unknown     yes  \n",
            "4    5   may       673         2     -1         0  unknown     yes  \n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oBV9bGXhDVNu",
        "outputId": "469ef360-ddc2-4bf7-c098-3a2bedd39c2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2: Rescaling a Feature (MinMax Scaling)**"
      ],
      "metadata": {
        "id": "kYS6ODDgDVNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will rescale 'age' to be between 0 and 1\n",
        "feature_age = df[['age']].values\n",
        "minmax_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
        "scaled_age = minmax_scaler.fit_transform(feature_age)\n",
        "\n",
        "print(\"Scaled Age (First 5 values):\")\n",
        "print(scaled_age[:5].flatten())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Age (First 5 values):\n",
            "[0.53246753 0.49350649 0.2987013  0.48051948 0.46753247]\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SoBKYLpLDVNw",
        "outputId": "f8c585fe-8b78-4b83-948e-3ab0d3276476"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3: Standardizing a Feature (Z-Score & Robust)**"
      ],
      "metadata": {
        "id": "CONskECIDVNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize 'balance' so it has mean=0 and std=1\n",
        "feature_balance = df[['balance']].values\n",
        "scaler = preprocessing.StandardScaler()\n",
        "standardized_balance = scaler.fit_transform(feature_balance)\n",
        "\n",
        "print(\"Standardized Balance (Mean and Std):\")\n",
        "print(f\"Mean: {round(standardized_balance.mean())}\")\n",
        "print(f\"Std: {standardized_balance.std()}\")\n",
        "\n",
        "# Robust Scaler (Less sensitive to outliers)\n",
        "robust_scaler = preprocessing.RobustScaler()\n",
        "robust_balance = robust_scaler.fit_transform(feature_balance)\n",
        "print(\"\\nRobust Scaled Balance (First 5):\")\n",
        "print(robust_balance[:5].flatten())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized Balance (Mean and Std):\n",
            "Mean: 0\n",
            "Std: 1.0\n",
            "\n",
            "Robust Scaled Balance (First 5):\n",
            "[ 1.13051702 -0.3184111   0.45397226  1.21437579 -0.23076923]\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0vkZ4PqzDVNw",
        "outputId": "8982674a-3e51-437d-a6d5-91128f611653"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4: Normalizing Observations**"
      ],
      "metadata": {
        "id": "uMeaOTlaDVNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize 'duration' and 'campaign' (length 1)\n",
        "features_norm = df[['duration', 'campaign']].values\n",
        "normalizer = Normalizer(norm=\"l2\")\n",
        "normalized_features = normalizer.transform(features_norm)\n",
        "\n",
        "print(\"Normalized Duration & Campaign (First 5 rows):\")\n",
        "print(normalized_features[:5])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Duration & Campaign (First 5 rows):\n",
            "[[9.99999539e-01 9.59692456e-04]\n",
            " [9.99999768e-01 6.81663100e-04]\n",
            " [9.99999741e-01 7.19942218e-04]\n",
            " [9.99998509e-01 1.72711314e-03]\n",
            " [9.99995584e-01 2.97175508e-03]]\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AwVKoAY5DVNw",
        "outputId": "49e60c4e-0c93-403f-b76c-a9aab34dda42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5: Grouping Observations Using Clustering**"
      ],
      "metadata": {
        "id": "4i_AlANQDVNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group customers into 3 clusters based on 'age' and 'balance'\n",
        "features_cluster = df[['age', 'balance']].values\n",
        "clusterer = KMeans(3, random_state=0)\n",
        "df['cluster_group'] = clusterer.fit_predict(features_cluster)\n",
        "\n",
        "print(\"Clustered Groups (First 5 rows):\")\n",
        "print(df[['age', 'balance', 'cluster_group']].head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustered Groups (First 5 rows):\n",
            "   age  balance  cluster_group\n",
            "0   59     2343              1\n",
            "1   56       45              1\n",
            "2   41     1270              1\n",
            "3   55     2476              1\n",
            "4   54      184              1\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GpkeNnJkDVNx",
        "outputId": "4a88bd41-090e-46cc-e79e-01fb7b8ca7de"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6: Handling Missing Numerical Values**"
      ],
      "metadata": {
        "id": "TH19cUewDVNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bank.csv is clean, so we artificially create missing values in 'pdays'\n",
        "df_missing = df.copy()\n",
        "df_missing.loc[0:10, 'pdays'] = np.nan\n",
        "\n",
        "imputer_mean = SimpleImputer(strategy=\"mean\")\n",
        "imputed_pdays = imputer_mean.fit_transform(df_missing[['pdays']])\n",
        "\n",
        "print(\"Imputed 'pdays' (First 5 values - originally NaNs):\")\n",
        "print(imputed_pdays[:5].flatten())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputed 'pdays' (First 5 values - originally NaNs):\n",
            "[51.38202852 51.38202852 51.38202852 51.38202852 51.38202852]\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zD5ENlPADVNy",
        "outputId": "6115f5ff-9495-4471-a928-fa6caf8f99a2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### **Part 2: Handling Categorical Data & Imbalanced Classes**\n",
        "\n",
        "**7: Imports for Categorical Data**"
      ],
      "metadata": {
        "id": "GIzswGHmDVNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Reload dataset to ensure clean slate for Part 2\n",
        "df = pd.read_csv('bank.csv')"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "id": "C3e13FK3DVNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8: Encoding Nominal Categorical Features**"
      ],
      "metadata": {
        "id": "NLBPRg2VDVNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using LabelBinarizer for 'marital' status\n",
        "feature_marital = df[['marital']].values\n",
        "one_hot = LabelBinarizer()\n",
        "marital_encoded = one_hot.fit_transform(feature_marital)\n",
        "\n",
        "print(\"One-Hot Encoded 'marital' (First 5 rows):\")\n",
        "print(marital_encoded[:5])\n",
        "print(\"Classes:\", one_hot.classes_)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-Hot Encoded 'marital' (First 5 rows):\n",
            "[[0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [0 1 0]]\n",
            "Classes: ['divorced' 'married' 'single']\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EXW9apSeDVNy",
        "outputId": "fba15359-9c43-4052-eb3b-8c06c2d34a54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9: Encoding Dictionaries of Features**"
      ],
      "metadata": {
        "id": "Ke7UbjrWDVNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'job' and 'education' to a dictionary and then vectorize\n",
        "data_dict = df[['job', 'education']].to_dict(orient='records')\n",
        "dictvectorizer = DictVectorizer(sparse=False)\n",
        "features_dict = dictvectorizer.fit_transform(data_dict)\n",
        "\n",
        "print(\"Dictionary Vectorized Features (First row):\")\n",
        "print(features_dict[0])\n",
        "print(\"Feature Names:\", dictvectorizer.get_feature_names_out()[:5])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary Vectorized Features (First row):\n",
            "[0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Feature Names: ['education=primary' 'education=secondary' 'education=tertiary'\n",
            " 'education=unknown' 'job=admin.']\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o4PKYSRvDVNy",
        "outputId": "c6ad4606-ef3a-4f75-d8ba-2fc884b44b5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10: Encoding Ordinal Categorical Features (Binning)**"
      ],
      "metadata": {
        "id": "YNvDbiphDVNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bin 'age' into logical groups: Young, Middle, Senior\n",
        "df['age_group'] = pd.cut(df['age'], bins=[0, 30, 55, 100], labels=[\"Young\", \"Middle\", \"Senior\"])\n",
        "\n",
        "# Map labels to numeric values\n",
        "scale_mapper = {\"Young\": 1, \"Middle\": 2, \"Senior\": 3}\n",
        "df['age_group_encoded'] = df['age_group'].map(scale_mapper)\n",
        "\n",
        "print(\"Binned and Encoded Age (First 5 rows):\")\n",
        "print(df[['age', 'age_group', 'age_group_encoded']].head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binned and Encoded Age (First 5 rows):\n",
            "   age age_group age_group_encoded\n",
            "0   59    Senior                 3\n",
            "1   56    Senior                 3\n",
            "2   41    Middle                 2\n",
            "3   55    Middle                 2\n",
            "4   54    Middle                 2\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3QVEE1R9DVNy",
        "outputId": "7e3be41c-9eb4-4f6c-cac8-2006167d0bbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11: Imputing Missing Class Values (using KNN)**"
      ],
      "metadata": {
        "id": "cPVgBvdMDVNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict missing 'loan' values using 'age' and 'balance'\n",
        "X_knn = df[['age', 'balance']].values\n",
        "y_knn = df['loan'].values\n",
        "\n",
        "# Create training set (skipping first 10 rows to simulate them as \"missing\")\n",
        "X_train = X_knn[10:]\n",
        "y_train = y_knn[10:]\n",
        "\n",
        "# Train KNN\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "clf_knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict for a \"missing\" row (e.g., row 0)\n",
        "predicted_loan = clf_knn.predict([X_knn[0]])\n",
        "print(f\"Predicted missing 'loan' value for row 0: {predicted_loan[0]}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted missing 'loan' value for row 0: no\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IZfDle9FDVNz",
        "outputId": "b6dc76c7-f8a3-44b9-90f3-d75d45b2c589"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12: Handling Imbalanced Classes**"
      ],
      "metadata": {
        "id": "MIl5O62vDVNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check balance of target 'deposit'\n",
        "print(\"Target Distribution:\")\n",
        "print(df['deposit'].value_counts())\n",
        "\n",
        "# Downsample the majority class ('no')\n",
        "i_class_no = np.where(df['deposit'] == 'no')[0]\n",
        "i_class_yes = np.where(df['deposit'] == 'yes')[0]\n",
        "\n",
        "# Downsample 'no' to match 'yes' count\n",
        "n_yes = len(i_class_yes)\n",
        "downsampled_no_indices = np.random.choice(i_class_no, size=n_yes, replace=False)\n",
        "\n",
        "# Combine indices\n",
        "final_indices = np.hstack((i_class_yes, downsampled_no_indices))\n",
        "df_balanced = df.iloc[final_indices]\n",
        "\n",
        "print(\"\\nBalanced Target Distribution (After Downsampling):\")\n",
        "print(df_balanced['deposit'].value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Distribution:\n",
            "deposit\n",
            "no     5873\n",
            "yes    5289\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balanced Target Distribution (After Downsampling):\n",
            "deposit\n",
            "yes    5289\n",
            "no     5289\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TSyAgpnyDVNz",
        "outputId": "aaec857c-4136-4e34-880f-5596457ec43f"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}