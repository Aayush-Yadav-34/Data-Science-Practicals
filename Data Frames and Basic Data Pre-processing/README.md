# ğŸ“ˆ Analysis: Data Frames and Basic Data Pre-processing

[View the Notebook: Data Frames and Basic Data Pre-processing.ipynb](./Data Frames and Basic Data Pre-processing.ipynb)

## Project Focus
The goal of this analysis was to master fundamental data loading and manipulation techniques using the Python Pandas library.

* Read data from various file types (CSV, Excel, JSON, and SQLite Database).
* Implement standard data cleaning tasks, including handling missing values.
* Apply core data transformations such as filtering, sorting, grouping, and aggregation.

---

## ğŸ“ Analysis Content Summary

The notebook covers the following key data science operations:

### Data Loading and Creation
* Demonstrates fetching structured data from multiple formats (CSV, Excel, JSON, SQL Database).
* Creates simulated datasets using `sklearn.datasets` for Regression, Classification, and Clustering.

### Data Inspection and Manipulation
* Uses `.shape`, `.head()`, and `.describe()` for quick data profiling.
* Accesses data using both index-based (`.iloc`) and label-based (`.loc`) selection.
* Applies conditional filtering using Boolean logic.
* Performs data cleaning by identifying missing values (`.isnull()`) and dropping columns/rows.
* Transforms data by renaming columns, replacing values, and applying custom functions (`.apply()`).
* Aggregates data using `.groupby()` to find statistics like mean age per gender and survival status.

---

## ğŸ“‚ Data Files Used

All required data files are located in the parent **`../Datasets/`** folder.
