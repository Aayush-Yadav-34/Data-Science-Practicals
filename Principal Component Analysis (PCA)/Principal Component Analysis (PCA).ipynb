{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**SHETH L.U.J. & SIR M.V. COLLEGE**\n",
        "\n",
        "Aayush D. Yadav | T123\n",
        "\n",
        "Practical No. 9\n",
        "\n",
        "Aim: Principal Component Analysis (PCA)\n",
        "\n",
        "\n",
        "*   Perform PCA on a dataset to reduce dimensionality.\n",
        "*   Evaluate the explained variance and select the appropriate number of principal\n",
        "components.\n",
        "\n",
        "*    Visualize the data in the reduced-dimensional space.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oJSwvHLc3S54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1\\. Reducing Features Using Principal Components"
      ],
      "metadata": {
        "id": "coVZLC655ssM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdB7zhmf21eI",
        "outputId": "8faa46c1-7460-460a-86c1-a2e9520a152d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of features: 11\n",
            "Reduced number of features: 10\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('winequality-red.csv')\n",
        "X = df.drop('quality', axis=1).values  # Drop target column if present (you can adjust!)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Create a PCA that will retain 99% of the variance\n",
        "pca = PCA(n_components=0.99, whiten=True)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(\"Original number of features:\", X.shape[1])\n",
        "print(\"Reduced number of features:\", X_pca.shape[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\\. Reducing Features When Data Is Linearly Inseparable"
      ],
      "metadata": {
        "id": "olOjY0OE5ssQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "# Use two numerical columns for kernel PCA (adjust if your dataset has other columns)\n",
        "features = df[['alcohol', 'pH']].values\n",
        "\n",
        "# Apply kernel PCA with rbf kernel\n",
        "kpca = KernelPCA(kernel=\"rbf\", gamma=15, n_components=1)\n",
        "features_kpca = kpca.fit_transform(features)\n",
        "\n",
        "print(\"Original number of features:\", features.shape[1])\n",
        "print(\"Reduced number of features:\", features_kpca.shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_vN9n3G5Br1",
        "outputId": "4aa1c23b-1dcc-43b8-c739-0486d93a6cc5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of features: 2\n",
            "Reduced number of features: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3\\. Reducing Features by Maximizing Class Separability"
      ],
      "metadata": {
        "id": "tzOuHpRQ5ssR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Example: Use all features except the target ('quality')\n",
        "X = df.drop('quality', axis=1).values\n",
        "y = df['quality'].values\n",
        "\n",
        "# Reduce to 1 feature/component maximizing class separability\n",
        "lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "X_lda = lda.fit_transform(X, y)\n",
        "\n",
        "print(\"Original number of features:\", X.shape[1])\n",
        "print(\"Reduced number of features:\", X_lda.shape[1])\n",
        "print(\"Explained variance ratio:\", lda.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE_qF5jq5GHj",
        "outputId": "cb5b5a81-866d-4f7d-8933-e7e4232c6914"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of features: 11\n",
            "Reduced number of features: 1\n",
            "Explained variance ratio: [0.84961759]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}